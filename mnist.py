# -*- coding: utf-8 -*-
"""MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Uqtvjbe6NDS0zXmVhhWxH9dgQ2SpGyAZ
"""

#Import Libraries
#import pytorch
import torch
from torch import nn
#import torchvision
import torchvision
from torchvision import datasets
from torchvision import transforms
from torchvision.transforms import ToTensor
#Visualize
import matplotlib.pyplot as plt

#device agnostic code
device = "cuda" if torch.cuda.is_available() else "cpu"

train_data = datasets.MNIST(root="data", train=True, download=True, transform=ToTensor(), target_transform=None)
test_data = datasets.MNIST(root="data", train=False, download=True, transform=ToTensor(), target_transform=None)

class_names = train_data.classes

#Dataloader
from torch.utils.data import DataLoader

train_dataloader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)
test_dataloader = DataLoader(dataset=test_data, batch_size=32, shuffle=False)

#Model
model = nn.Sequential(
    nn.Flatten(),
    nn.Linear(in_features=784, out_features=20),
    nn.Linear(in_features=20, out_features=len(class_names))
)
model

#loss and optimizer
loss_fn = nn.CrossEntropyLoss()
optimizer=torch.optim.Adam(params=model.parameters(), lr=0.001)

#accuracy function
def accuracy_fn(y_true, y_pred):
  correct = torch.eq(y_true, y_pred).sum().item()
  acc = (correct/len(y_pred)) * 100
  return acc

#Training loop
torch.manual_seed(42)

epochs=20

for epoch in range(epochs):
  train_loss, train_acc = 0, 0
  model.to(device)
  for batch, (X,y) in enumerate(train_dataloader):
    model.train()
    X, y = X.to(device), y.to(device)
    y_pred=model(X)
    loss = loss_fn(y_pred, y)
    train_loss += loss
    train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
  train_loss /=len(train_dataloader)
  train_acc /=len(train_dataloader)
  test_loss, test_acc = 0, 0
  model.to(device)
  model.eval()
  with torch.inference_mode():
    for X,y in test_dataloader:
      X, y = X.to(device), y.to(device)
      test_pred = model(X)
      test_loss += loss_fn(test_pred, y)
      test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))
    test_loss /=len(test_dataloader)
    test_acc /=len(test_dataloader)
  if epoch%5==0:
    print(f' Epoch: {epoch} | Train Loss: {train_loss:.5f} | Train Acc: {train_acc:.3f} | Test Loss: {test_loss:.5f} | Test Acc: {test_acc:.3f}')

#Predictions
def make_predictions(model:torch.nn.Module,
                     data: list,
                     device: torch.device=device):
  pred_probs=[]
  model.to(device)
  model.eval()
  with torch.inference_mode():
    for sample in data:
      sample = torch.unsqueeze(sample, dim=0).to(device)
      pred_logit = model(sample)
      pred_prob = torch.softmax(pred_logit.squeeze(),dim=0)
      pred_probs.append(pred_prob.cpu())
  return torch.stack(pred_probs)

import random
random.seed(42)
test_samples=[]
test_labels=[]
for sample, label in random.sample(list(test_data), k=9):
  test_samples.append(sample)
  test_labels.append(label)
test_samples[0].shape

#make predictions
pred_probs = make_predictions(model=model,
                              data=test_samples)

pred_classes = pred_probs.argmax(dim=1)

#plot predictions
plt.figure(figsize=(9,9))
nrows=3
ncols=3
for i, sample in enumerate(test_samples):
  plt.subplot(nrows, ncols, i+1)
  plt.imshow(sample.squeeze(), cmap="gray")
  pred_label= class_names[pred_classes[i]]
  truth_label = class_names[test_labels[i]]
  title_text = f"Pred : {pred_label} | Truth: {truth_label}"
  if pred_label == truth_label:
    plt.title(title_text, fontsize=10, c="g")
  else:
    plt.title(title_text, fontsize=10, c="r")
  plt.axis(False)

#confusion matrix
from tqdm.auto import tqdm

y_preds=[]
model.eval()
with torch.inference_mode():
  for X, y in tqdm(test_dataloader, desc="Making Predictions"):
    X, y = X.to(device), y.to(device)
    y_logits = model(X)
    y_pred = torch.softmax(y_logits.squeeze(), dim=0).argmax(dim=1)
    y_preds.append(y_pred.cpu())

  y_pred_tensor = torch.cat(y_preds)
  y_pred_tensor
from torchmetrics import ConfusionMatrix
from mlxtend.plotting import plot_confusion_matrix

confmat = ConfusionMatrix(num_classes=len(class_names), task="Multiclass")
confmat_tensor = confmat(preds=y_pred_tensor, target=test_data.targets)

fig ,ax= plot_confusion_matrix(
    conf_mat = confmat_tensor.numpy(),
    class_names=class_names,
    figsize=(10,7)
)

#Save and Load
from pathlib import Path

model_path = Path("model")
model_path.mkdir(parents=True,
                 exist_ok = True)
model_name = "MNIST.pth"

model_save_path = model_path / model_name
model_save_path

torch.save(obj=model.state_dict(), f =model_save_path)

